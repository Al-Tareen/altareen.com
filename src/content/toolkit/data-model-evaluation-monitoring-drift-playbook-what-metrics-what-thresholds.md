---
title: "Monitoring & drift playbook (what metrics, what thresholds)"
primaryCategory: "Data & Model Evaluation"
categories: ["Data & Model Evaluation"]
dbTitle: "Frameworks"
notionId: "2db39950-eddd-80f2-9f69-ec61c5fd5865"
link: ""
---
## When to use
When an AI feature is live (or about to go live) and you need to detect quality decay, drift, or abuse fast.

## Inputs required
Instrumentation events; quality signals; thresholds; on-call ownership; dashboards tools.

## Output artifact
Monitoring plan; alert rules; dashboards; runbooks for common failures.

## Common mistakes
Monitoring uptime only; no quality monitoring; alert fatigue; unclear ownership.
