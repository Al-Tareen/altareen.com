---
title: "Model behavior test plan (red teaming-lite)"
primaryCategory: "AI Product Quality, Risk & Safety"
categories: ["AI Product Quality, Risk & Safety"]
dbTitle: "Frameworks"
notionId: "2db39950-eddd-8007-ac36-fc38e85fbb37"
link: ""
---
## When to use
When you suspect the model may hallucinate, jailbreak, or produce unsafe outputsâ€”and you need to test it before launch.

## Inputs required
Abuse prompts; adversarial scenarios; policy rules; golden set; known failure modes.

## Output artifact
Red-team suite; results; fixes; re-test cadence.

## Common mistakes
Only testing normal users; no jailbreak attempts; no retest after fixes.
