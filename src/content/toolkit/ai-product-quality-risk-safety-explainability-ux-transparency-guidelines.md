---
title: "Explainability & UX transparency guidelines"
primaryCategory: "AI Product Quality, Risk & Safety"
categories: ["AI Product Quality, Risk & Safety"]
whenToUse: "When users might overtrust AI outputs and you must set expectations (confidence, sources, limitations)."
inputsRequired: "Model limitations; uncertainty patterns; disclosure requirements; user trust risks."
outputArtifact: "UX rules for transparency (confidence cues, citations, disclaimers, feedback capture)."
commonMistakes: "Overpromising; hiding uncertainty; confusing UX; no feedback loop."
dbTitle: "Frameworks"
notionId: "2db39950-eddd-80c7-b779-c056706b18b6"
link: ""
cover: "/toolkit-covers/ai-product-quality-risk-safety-explainability-ux-transparency-guidelines.png"
files: []
---
## When to use
When users might overtrust AI outputs and you must set expectations (confidence, sources, limitations).

## Inputs required
Model limitations; uncertainty patterns; disclosure requirements; user trust risks.

## Output artifact
UX rules for transparency (confidence cues, citations, disclaimers, feedback capture).

## Common mistakes
Overpromising; hiding uncertainty; confusing UX; no feedback loop.
