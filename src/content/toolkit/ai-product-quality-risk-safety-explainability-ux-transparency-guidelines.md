---
title: "Explainability & UX transparency guidelines"
primaryCategory: "AI Product Quality, Risk & Safety"
categories: ["AI Product Quality, Risk & Safety"]
dbTitle: "Frameworks"
notionId: "2db39950-eddd-80c7-b779-c056706b18b6"
link: ""
---
## When to use
When users might overtrust AI outputs and you must set expectations (confidence, sources, limitations).

## Inputs required
Model limitations; uncertainty patterns; disclosure requirements; user trust risks.

## Output artifact
UX rules for transparency (confidence cues, citations, disclaimers, feedback capture).

## Common mistakes
Overpromising; hiding uncertainty; confusing UX; no feedback loop.
