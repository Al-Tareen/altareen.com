---
title: "Guardrails & escalation policy (what happens when model fails)"
primaryCategory: "AI Product Quality, Risk & Safety"
categories: ["AI Product Quality, Risk & Safety"]
dbTitle: "Frameworks"
notionId: "2db39950-eddd-8040-aa9c-f396e91ee507"
link: ""
---
## When to use
When failures would harm trust and you need clear behavior for refusal, fallback, and escalation.

## Inputs required
Failure modes; confidence/quality thresholds; fallback options; escalation owners; logging.

## Output artifact
Guardrail rules (refuse/fallback/hand-off); escalation map; severity levels.

## Common mistakes
Over-restricting (kills UX) or under-restricting (unsafe); vague thresholds; no fallback.
