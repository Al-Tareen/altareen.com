---
title: "LLM Vendor / Model Selection Scorecard"
primaryCategory: "Data & Model Evaluation"
categories: ["Data & Model Evaluation"]
whenToUse: "When you’re choosing between vendors/models and need to balance quality, cost, latency, privacy, and lock-in."
inputsRequired: "Requirements (quality/latency/cost/privacy); eval results; contract terms; data retention policies."
outputArtifact: "Weighted scorecard; recommended vendor/model tiering; decision record + rationale."
commonMistakes: "Choosing by hype; skipping eval on real data; ignoring retention/compliance; no exit plan."
dbTitle: "Frameworks"
notionId: "2db39950-eddd-8005-a818-f0ce09b1b735"
link: ""
cover: "/toolkit-covers/data-model-evaluation-llm-vendor-model-selection-scorecard.png"
files: []
---
## When to use
When you’re choosing between vendors/models and need to balance quality, cost, latency, privacy, and lock-in.

## Inputs required
Requirements (quality/latency/cost/privacy); eval results; contract terms; data retention policies.

## Output artifact
Weighted scorecard; recommended vendor/model tiering; decision record + rationale.

## Common mistakes
Choosing by hype; skipping eval on real data; ignoring retention/compliance; no exit plan.
