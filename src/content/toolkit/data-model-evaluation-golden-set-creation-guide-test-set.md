---
title: "Golden set creation guide (test set)"
primaryCategory: "Data & Model Evaluation"
categories: ["Data & Model Evaluation"]
whenToUse: "When quality is subjective and you need a stable test set to prevent “it feels better” arguments."
inputsRequired: "Representative cases; edge cases; labeling guidelines; adjudication process; version control."
outputArtifact: "Curated test set; labeling rubric; dataset versions; coverage report."
commonMistakes: "Biased sampling; missing edge cases; label inconsistency; not versioned."
dbTitle: "Frameworks"
notionId: "2db39950-eddd-80c2-8ffa-f22d511597db"
link: ""
cover: "/toolkit-covers/data-model-evaluation-golden-set-creation-guide-test-set.png"
files: []
---
## When to use
When quality is subjective and you need a stable test set to prevent “it feels better” arguments.

## Inputs required
Representative cases; edge cases; labeling guidelines; adjudication process; version control.

## Output artifact
Curated test set; labeling rubric; dataset versions; coverage report.

## Common mistakes
Biased sampling; missing edge cases; label inconsistency; not versioned.
