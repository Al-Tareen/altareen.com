---
title: "Evaluation Metrics Catalog (Task-specific)"
primaryCategory: "Data & Model Evaluation"
categories: ["Data & Model Evaluation"]
dbTitle: "Frameworks"
notionId: "2db39950-eddd-8033-84f9-f1f69ba87f5d"
link: ""
---
## When to use
When you must choose a model/prompt approach and need a repeatable, defensible way to compare options.

## Inputs required
Golden set; metrics definitions; baseline approach; acceptance thresholds; test harness.

## Output artifact
Eval plan; scorecards; ship/no-ship thresholds; comparison results.

## Common mistakes
No thresholds; metrics donâ€™t match user value; offline-only; no baseline comparison.
